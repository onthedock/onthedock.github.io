<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ops on On The Dock</title>
    <link>https://onthedock.github.io/categories/ops/</link>
    <description>Recent content in ops on On The Dock</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Handmade with &amp;#9829; by Xavi Aznar</copyright>
    <lastBuildDate>Thu, 30 Dec 2021 12:12:02 +0100</lastBuildDate><atom:link href="https://onthedock.github.io/categories/ops/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>¿Por qué los Deployments usan Replicasets pero los Statefulsets y los Daemonsets no?</title>
      <link>https://onthedock.github.io/post/211230-porque-los-deployments-usan-replicasets-pero-no-los-statefulsets-ni-los-daemonsets/</link>
      <pubDate>Thu, 30 Dec 2021 12:12:02 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/211230-porque-los-deployments-usan-replicasets-pero-no-los-statefulsets-ni-los-daemonsets/</guid>
      <description>&lt;p&gt;Revisando el &lt;em&gt;feed&lt;/em&gt; del foro de Kubernetes &lt;a href=&#34;https://discuss.kubernetes.io/&#34;&gt;discuss.kubernetes.io&lt;/a&gt;, me llamó la atención la pregunta de &lt;code&gt;user2&lt;/code&gt; &lt;a href=&#34;https://discuss.kubernetes.io/t/why-deployment-need-replicaset-but-daemonset-and-statefulset-dont-need/18334&#34;&gt;Why deployment need replicaset, but daemonset and statefulset don’t need&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://discuss.kubernetes.io/t/why-deployment-need-replicaset-but-daemonset-and-statefulset-dont-need/18334/2?u=xavi&#34;&gt;Respondí en el foro&lt;/a&gt;, pero quiero ampliar la respuesta aquí.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Crear usuarios (usando recursos nativos) en Kubernetes 1.19&#43;</title>
      <link>https://onthedock.github.io/post/211205-crear-usuarios-usando-recursos-nativos-en-kubernetes-1.19/</link>
      <pubDate>Sun, 05 Dec 2021 19:57:28 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/211205-crear-usuarios-usando-recursos-nativos-en-kubernetes-1.19/</guid>
      <description>&lt;p&gt;Hace unas entradas, en &lt;a href=&#34;https://onthedock.github.io/post/211010-crear-usuarios-en-k3s/&#34;&gt;
Crear usuarios en Kubernetes (y en K3s)&lt;/a&gt;, escribía sobre cómo generar nuevos usuarios con acceso al clúster de Kubernetes usando un fichero &lt;code&gt;kubeconfig&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;El método descrito implicaba extraer fuera del clúster el certificado privado de la entidad certificadora (CA) de Kubernetes, lo que no me parecía la mejor solución.&lt;/p&gt;
&lt;p&gt;Desde Kubernetes 1.19 existe un nuevo recurso en la API, el &lt;code&gt;CertificateSigningRequest&lt;/code&gt;, que permite firmar certificados para proporcionar acceso (por ejemplo) al clúster.&lt;/p&gt;
&lt;p&gt;En esta entrada se describe cómo aprovechar esta nueva funcionalidad para dar acceso a un usuario usando un certificado firmado por la CA del clúster.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatiza la instalación de Longhorn</title>
      <link>https://onthedock.github.io/post/211113-automatiza-la-instalacion-de-longhorn/</link>
      <pubDate>Sat, 13 Nov 2021 19:53:33 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/211113-automatiza-la-instalacion-de-longhorn/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://longhorn.io/&#34;&gt;Longhorn&lt;/a&gt; es una solución de almacenamiento distribuido de bloques para Kubernetes. Recientemente ha sido incluido en la &lt;a href=&#34;https://www.cncf.io/blog/2021/11/04/longhorn-brings-cloud-native-distributed-storage-to-the-cncf-incubator/&#34;&gt;&lt;em&gt;incubadora&lt;/em&gt; de la CNCF&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Longhorn proporciona métricas para Prometheus y es el complemento perfecto para proporcionar almacenamiento a las aplicaciones desplegadas sobre Kubernetes.&lt;/p&gt;
&lt;p&gt;En esta entrada automatizamos las &lt;a href=&#34;https://longhorn.io/docs/1.2.2/deploy/install/install-with-helm/&#34;&gt;instrucciones oficiales&lt;/a&gt; de despliegue usando Helm para desplegarlo sobre Kubernetes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Actualizar k3s con k3sup</title>
      <link>https://onthedock.github.io/post/211111-actualizar-k3s-con-k3sup/</link>
      <pubDate>Thu, 11 Nov 2021 21:32:41 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/211111-actualizar-k3s-con-k3sup/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/alexellis/k3sup&#34;&gt;k3sup&lt;/a&gt; es una herramienta que permite instalar clústers de Kubernetes basados en &lt;a href=&#34;https://k3s.io/&#34;&gt;K3s&lt;/a&gt; &lt;a href=&#34;https://github.com/alexellis/k3sup#demo-&#34;&gt;en menos de un minuto&lt;/a&gt;. Pero acabo de descubrir que además, también permite actualizar el clúster.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Script para crear usuarios en Kubernetes (y en K3s)</title>
      <link>https://onthedock.github.io/post/211010-crear-usuarios-en-k3s-script/</link>
      <pubDate>Sun, 10 Oct 2021 08:51:51 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/211010-crear-usuarios-en-k3s-script/</guid>
      <description>&lt;p&gt;El &lt;em&gt;script&lt;/em&gt; automatiza el proceso completo de creación de un usuario en Kubernetes. Como el proceso es algo diferente en K3s, esta entrada se centra más en este caso &lt;em&gt;especial&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Crear usuarios en Kubernetes (y en K3s)</title>
      <link>https://onthedock.github.io/post/211010-crear-usuarios-en-k3s/</link>
      <pubDate>Sun, 10 Oct 2021 07:08:56 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/211010-crear-usuarios-en-k3s/</guid>
      <description>&lt;p&gt;En Kubernetes no existe el concepto de usuario; sólo se confía en quien presente un certificado firmado por la CA del clúster.&lt;/p&gt;
&lt;p&gt;Para obtener los certificados de la CA, lo más sencillo es acceder a un nodo &lt;em&gt;server&lt;/em&gt;; los certificados (&lt;code&gt;ca.cert&lt;/code&gt; y &lt;code&gt;ca.key&lt;/code&gt;) se encuentran en &lt;code&gt;/etc/kubernetes/pki/&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Existe otra opción que pasa por generar un objeto &lt;code&gt;CertificateSigningRequest&lt;/code&gt; para firmar el certificado de usuario.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;El proceso implica generar un certificado al usuario, solicitar que lo firme la &lt;em&gt;Certificate Authority&lt;/em&gt; del clúster y después autenticarse con él.&lt;/p&gt;
&lt;p&gt;Para poder autenticarse en el clúster, necesitamos configurar un cliente, por ejemplo creando un fichero &lt;code&gt;kubeconfig&lt;/code&gt; para &lt;strong&gt;kubectl&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Finalmente, el nuevo usuario debe estar autorizado a realizar algunas acciones en el clúster; para ello definiremos un conjunto de permisos en un &lt;em&gt;Role&lt;/em&gt; o un &lt;em&gt;ClusterRole&lt;/em&gt; y lo asociaremos al usuario mediante un &lt;em&gt;RoleBinding&lt;/em&gt; (o un &lt;em&gt;ClusterRoleBinding&lt;/em&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Creación de Sealed Secrets (SealedSecrets-II)</title>
      <link>https://onthedock.github.io/post/210819-sealed-secrets-ii/</link>
      <pubDate>Thu, 19 Aug 2021 21:12:30 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/210819-sealed-secrets-ii/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://onthedock.github.io/post/210819-sealed-secrets/&#34;&gt;Instalación de SealedSecrets (SealedSecrets - I)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://onthedock.github.io/post/210819-sealed-secrets-ii/&#34;&gt;Creación de SealedSecrets (SealedSecrets - II)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Instalación de Sealed Secrets (SealedSecrets-I)</title>
      <link>https://onthedock.github.io/post/210819-sealed-secrets/</link>
      <pubDate>Thu, 19 Aug 2021 20:18:20 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/210819-sealed-secrets/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://onthedock.github.io/post/210819-sealed-secrets/&#34;&gt;Instalación de SealedSecrets (SealedSecrets - I)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://onthedock.github.io/post/210819-sealed-secrets-ii/&#34;&gt;Creación de SealedSecrets (SealedSecrets - II)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Uno de los problemas abiertos de Kubernetes es la gestión de los &lt;em&gt;secretos&lt;/em&gt;; es decir, aquella información sensible que, al menos de momento, se guarda en texto plano y cuya única medida de &amp;ldquo;seguridad&amp;rdquo; consiste en codificarla en &lt;a href=&#34;https://es.wikipedia.org/wiki/Base64&#34;&gt;base64&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Tal y como se indica en el &lt;code&gt;README.md&lt;/code&gt; de &lt;a href=&#34;https://github.com/bitnami-labs/sealed-secrets&#34;&gt;Sealed Secrets&lt;/a&gt;, &lt;strong&gt;puedes gestionar toda la configuración de Kubernetes en Git&amp;hellip; excepto los &lt;em&gt;Secrets&lt;/em&gt;&lt;/strong&gt;, precisamente porque los &lt;em&gt;Secrets&lt;/em&gt; no son seguros&amp;hellip;&lt;/p&gt;
&lt;p&gt;Con el auge de metodologías como &lt;a href=&#34;https://www.weave.works/technologies/gitops/&#34;&gt;GitOps&lt;/a&gt;, el problema es mayor, ya que los desarrolladores no tienen acceso directo al clúster y &lt;strong&gt;todo&lt;/strong&gt; debe desplegarse automáticamente desde Git.&lt;/p&gt;
&lt;p&gt;Una de las soluciones al problema viene del equipo de &lt;a href=&#34;https://github.com/bitnami-labs/&#34;&gt;Bitnami-Labs&lt;/a&gt; con &lt;strong&gt;SealedSecrets&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Actualiza la versión de Alpine Linux</title>
      <link>https://onthedock.github.io/post/210712-actualiza-version-alpine/</link>
      <pubDate>Mon, 12 Jul 2021 18:36:49 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/210712-actualiza-version-alpine/</guid>
      <description>&lt;p&gt;Hace unos días actualicé la versión de &lt;a href=&#34;https://pop.system76.com/&#34;&gt;Pop_OS!&lt;/a&gt; en uno de los equipos de escritorio en los que tengo Linux instalado en casa.&lt;/p&gt;
&lt;p&gt;Hoy estaba revisando las máquinas virtuales y mientras actualizaba los paquetes de una VM con Ubuntu 20.04 he pensado cómo podría actualizar de Alpine 3.13 a la última versión publicada, Alpine 3.14.&lt;/p&gt;
&lt;p&gt;El proceso no puede ser más sencillo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Velero - Backup Y Disaster Recovery Para Kubernetes (III) Recuperación desde una copia de seguridad</title>
      <link>https://onthedock.github.io/post/210407-velero-backup-y-disaster-recovery-para-kubernetes-iii/</link>
      <pubDate>Wed, 07 Apr 2021 19:54:57 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/210407-velero-backup-y-disaster-recovery-para-kubernetes-iii/</guid>
      <description>&lt;p&gt;Velero realiza copias de seguridad (puntuales o recurrentes) para recuperarnos con rapidez de un desastre en el clúster de Kubernetes.&lt;/p&gt;
&lt;p&gt;En la entrada anterior &lt;a href=&#34;https://onthedock.github.io/post/210405-velero-backup-y-disaster-recovery-para-kubernetes-ii/&#34;&gt;Velero - Backup y Disaster Recovery para Kubernetes (II) Crear copia de seguridad&lt;/a&gt; desplegamos una aplicación de prueba en el clúster (dos réplicas de Nginx en el &lt;em&gt;Namespace&lt;/em&gt; &lt;code&gt;nginx-example&lt;/code&gt;). Simulamos la pérdida &amp;ldquo;accidental&amp;rdquo; del &lt;em&gt;Namespace&lt;/em&gt; &lt;code&gt;nginx-example&lt;/code&gt; para ver cómo recuperarnos usando la copia creada por Velero.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Velero - Backup y Disaster Recovery para Kubernetes (II) Crear copia de seguridad</title>
      <link>https://onthedock.github.io/post/210405-velero-backup-y-disaster-recovery-para-kubernetes-ii/</link>
      <pubDate>Mon, 05 Apr 2021 13:33:38 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/210405-velero-backup-y-disaster-recovery-para-kubernetes-ii/</guid>
      <description>&lt;p&gt;En la entrada anterior &lt;a href=&#34;https://onthedock.github.io/post/210405-velero-backup-y-disaster-recovery-para-kubernetes-ii/&#34;&gt;Velero - Backup y Disaster Recovery para Kubernetes (I) Instalación&lt;/a&gt; vimos cómo instalar Velero en Kubernetes. Usamos el comando &lt;code&gt;velero install&lt;/code&gt; lanzado desde un &lt;em&gt;Job&lt;/em&gt;  en la línea de la &lt;em&gt;filosofía&lt;/em&gt; GitOps.&lt;/p&gt;
&lt;p&gt;En esta entrada veremos cómo crear copias de seguridad puntuales y recurrentes usando la herramienta de línea de comandos &lt;strong&gt;velero&lt;/strong&gt; (lanzada desde un &lt;em&gt;Job&lt;/em&gt;)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Velero - Backup y Disaster Recovery para Kubernetes (I) Instalación</title>
      <link>https://onthedock.github.io/post/210405-velero-backup-y-disaster-recovery-para-kubernetes-i/</link>
      <pubDate>Mon, 05 Apr 2021 11:35:38 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/210405-velero-backup-y-disaster-recovery-para-kubernetes-i/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;htps:/velero.io&#34;&gt;Velero&lt;/a&gt; es una herramienta de código abierto que permite realizar copias de seguridad, restaurarlas y migrar recursos de Kubernetes entre clústers (lo que también permite recuperar un clúster en caso de desastre).&lt;/p&gt;
&lt;p&gt;Velero soporta diferentes proveedores en los que almacenar las copias de seguridad que realiza. La lista completa y actualizada se encuentra en &lt;a href=&#34;https://velero.io/docs/v1.5/supported-providers/&#34;&gt;Providers&lt;/a&gt;. En mi caso, voy a utilizar MinIO, que es compatible con AWS S3 y que tengo desplegado localmente en Kubernetes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Eliminar namespace encallado en Terminating</title>
      <link>https://onthedock.github.io/post/210305-eliminar-ns-terminating/</link>
      <pubDate>Fri, 05 Mar 2021 17:53:31 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/210305-eliminar-ns-terminating/</guid>
      <description>&lt;p&gt;Al hacer limpieza de uno de los clústers de desarrollo, he borrado dos &lt;em&gt;namespaces&lt;/em&gt; y los dos se han quedado en estado &lt;em&gt;Terminating&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Analiza los objetos de Kubernetes con Kubelinter y Cronjobs</title>
      <link>https://onthedock.github.io/post/210221-analiza-los-objetos-de-kubernetes-periodicamente-con-kubelinter-y-un-cronjob/</link>
      <pubDate>Sun, 21 Feb 2021 12:08:02 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/210221-analiza-los-objetos-de-kubernetes-periodicamente-con-kubelinter-y-un-cronjob/</guid>
      <description>&lt;p&gt;Idealmente, el análisis de los ficheros de definición de objetos (YAML) en Kubernetes debería realizarse &lt;strong&gt;antes&lt;/strong&gt; de crear los objetos en el clúster. Para ello, uno de los &lt;em&gt;stages&lt;/em&gt; del proceso de CI/CD debería incorporar KubeLinter (por ejemplo).&lt;/p&gt;
&lt;p&gt;De forma paralela, también deberíamos tener un proceso periódico que revise los ficheros de definición de los objetos que tenemos almacenados en el repositorio para identificar, por ejemplo, el uso de versiones de la API desaconsejadas (&lt;em&gt;deprecated&lt;/em&gt;) en proceso de eliminación de la API.&lt;/p&gt;
&lt;p&gt;En este artículo vemos cómo configurar un Cronjob que ejecute KubeLinter para obtener los ficheros de un repositorio remoto y analizarlos.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cómo saber si un recurso de Kubernetes está restringido al namespace o es global</title>
      <link>https://onthedock.github.io/post/201224-como-saber-si-un-recursos-esta-restringido-a-un-namespace/</link>
      <pubDate>Thu, 24 Dec 2020 11:39:07 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/201224-como-saber-si-un-recursos-esta-restringido-a-un-namespace/</guid>
      <description>&lt;p&gt;La mayoría de los recursos de Kubernetes como los &lt;em&gt;pods&lt;/em&gt;, los &lt;em&gt;services&lt;/em&gt;, los &lt;em&gt;replication controllers&lt;/em&gt;, etc están limitados al &lt;em&gt;namespace&lt;/em&gt; en el que se despliegan. Así, dos recursos pueden tener el mismo nombre, etc si se encuentran en &lt;em&gt;namespaces&lt;/em&gt; diferentes, ya que el &lt;em&gt;namespace&lt;/em&gt; define el &lt;em&gt;alcance&lt;/em&gt; de visibilidad para el recursos. El &lt;em&gt;namespace&lt;/em&gt; es el límite del &lt;em&gt;scope&lt;/em&gt; del recurso en Kubernetes.&lt;/p&gt;
&lt;p&gt;Sin embargo, no todos los recursos en Kubernetes se encuentran &amp;ldquo;limitados&amp;rdquo; por el &lt;em&gt;namespace&lt;/em&gt;; por ejemplo, el propio recurso &lt;code&gt;namespace&lt;/code&gt; no está en un &lt;em&gt;namespace&lt;/em&gt;, ni los &lt;code&gt;persistentVolumes&lt;/code&gt; tampoco&amp;hellip;&lt;/p&gt;
&lt;p&gt;¿Cómo podemos obtener una lista de los recursos con alcance restringido al &lt;em&gt;namespace&lt;/em&gt; en el que se encuentran?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Desplegar Gitea en Kubernetes</title>
      <link>https://onthedock.github.io/post/201212-desplegar-gitea-en-kubernetes/</link>
      <pubDate>Sat, 12 Dec 2020 12:13:18 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/201212-desplegar-gitea-en-kubernetes/</guid>
      <description>&lt;p&gt;Ya he hablado varias veces de &lt;a href=&#34;https://onthedock.github.io/tags/gitea&#34;&gt;Gitea en este sitio&lt;/a&gt;, así que no me repetiré (mucho)
; Gitea es una solución ligera de alojamiento de repositorios Git (a lo GitHub).&lt;/p&gt;
&lt;p&gt;En esta entrada se indica el proceso que he seguido para la creación de los diferentes objetos necesarios para desplegar Gitea (usando SQLite como base de datos) en Kubernetes.&lt;/p&gt;
&lt;p&gt;Puedes seguir los pasos de la &lt;a href=&#34;https://docs.gitea.io/en-us/install-on-kubernetes/&#34;&gt;documentación oficial para desplegar Gitea&lt;/a&gt; sobre Kubernetes usando Helm.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Actualizar el certificado de Traefik en K3s</title>
      <link>https://onthedock.github.io/post/201208-actualizar-el-certificado-de-traefik-en-k3s/</link>
      <pubDate>Tue, 08 Dec 2020 09:09:23 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/201208-actualizar-el-certificado-de-traefik-en-k3s/</guid>
      <description>&lt;p&gt;K3OS (y K3s) despliega Traefik como Ingress. Pero el problema es que el certificado autofirmado configurado por defecto caducó en 2017.&lt;/p&gt;
&lt;p&gt;Probablemente se trata de una &lt;em&gt;feature&lt;/em&gt; y no de un &lt;em&gt;bug&lt;/em&gt;, para &amp;ldquo;animar&amp;rdquo; a cambiar el certificado desplegado por defecto por uno válido; en este artículo explico cómo hacerlo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Interesante artículo &#34;More Problems with GitOps — and How to Fix Them&#34; en TheNewStack</title>
      <link>https://onthedock.github.io/post/201208-problemas-relacionados-con-gitops/</link>
      <pubDate>Tue, 08 Dec 2020 07:54:26 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/201208-problemas-relacionados-con-gitops/</guid>
      <description>&lt;p&gt;Hace unos días leía &lt;a href=&#34;https://thenewstack.io/more-problems-with-gitops-and-how-to-fix-them/&#34;&gt;More Problems with GitOps — and How to Fix Them&lt;/a&gt; sobre los problemas asociados a GitOps, así que aprovecho para inaugurar esta nueva sección de reflexiones sobre artículos que considero interesantes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Side Project: devtoolbox</title>
      <link>https://onthedock.github.io/post/201206-side-project/</link>
      <pubDate>Sun, 06 Dec 2020 22:02:24 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/201206-side-project/</guid>
      <description>&lt;p&gt;Ya hace casi dos meses de la última entrada en el blog; en esta entrada explico en qué he estado trabajando y qué me ha mantenido apartado de la publicación en el blog.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Resetear el password de administrador en Gitea</title>
      <link>https://onthedock.github.io/post/200925-resetear-el-password-del-admin-en-gitea/</link>
      <pubDate>Fri, 25 Sep 2020 21:31:30 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/200925-resetear-el-password-del-admin-en-gitea/</guid>
      <description>&lt;p&gt;Uno de los problemas de los entornos de laboratorio es que son &lt;em&gt;fungibles&lt;/em&gt;, casi de &amp;ldquo;usar y tirar&amp;rdquo;. Un efecto colateral es que cosas como las credenciales no se gestionan correctamente, se pone la primera que se nos ocurre y después&amp;hellip; pues no hay manera de volver a acceder.&lt;/p&gt;
&lt;p&gt;En mi caso me he encontrado en esta situación con Gitea y en esta entrada voy a documentar cómo establecer una nueva contraseña para el usuario &lt;em&gt;administrador&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Configurar hostname en K3OS</title>
      <link>https://onthedock.github.io/post/200923-configurar-hostname-en-k3os/</link>
      <pubDate>Wed, 23 Sep 2020 21:53:31 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/200923-configurar-hostname-en-k3os/</guid>
      <description>&lt;p&gt;Una de las cosas que no me resultó evidente al empezar a usar &lt;a href=&#34;https://k3os.io&#34;&gt;K3OS&lt;/a&gt; es que el sistema de ficheros tiene algunas &lt;em&gt;particularidades&lt;/em&gt; con las que es &lt;strong&gt;absolutamente&lt;/strong&gt; necesario estar familiarizado; por ejemplo, que toda la carpeta &lt;code&gt;/etc&lt;/code&gt; es &lt;strong&gt;EFÍMERA&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>IP estática en KVM</title>
      <link>https://onthedock.github.io/post/200710-ip-estatica-en-kvm/</link>
      <pubDate>Fri, 10 Jul 2020 18:16:34 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/200710-ip-estatica-en-kvm/</guid>
      <description>&lt;p&gt;Las máquinas virtuales en KVM obtienen una IP en el rango &lt;code&gt;192.168.122.2&lt;/code&gt; a &lt;code&gt;192.168.122.254&lt;/code&gt; (puedes comprobarlo mediante &lt;code&gt;virsh net-edit default&lt;/code&gt; (para la red &lt;em&gt;default&lt;/em&gt;)).&lt;/p&gt;
&lt;p&gt;Asignar una IP estática a una máquina virtual en KVM consiste en tres pasos:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Lanzar instancias en KVM y configurarlas con Cloudinit</title>
      <link>https://onthedock.github.io/post/200706-lanzar-instancias-en-kvm-y-configurarlas-con-cloudinit/</link>
      <pubDate>Mon, 06 Jul 2020 20:27:27 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/200706-lanzar-instancias-en-kvm-y-configurarlas-con-cloudinit/</guid>
      <description>&lt;p&gt;En la &lt;a href=&#34;https://onthedock.github.io/post/200627-creacion-de-vm-en-kvm-con-virsh/&#34;&gt;entrada anterior&lt;/a&gt; describía los pasos para lanzar una instancia en KVM usando &lt;code&gt;virsh&lt;/code&gt;. Pero aunque esto resuelve la creación de la máquina virtual, todavía tenemos que realizar la configuración manual del sistema operativo, establecer el &lt;code&gt;hostname&lt;/code&gt;, crear usuarios, instalar de paquetes, etc.&lt;/p&gt;
&lt;p&gt;Usando &lt;a href=&#34;https://cloudinit.readthedocs.io&#34;&gt;&lt;code&gt;cloud-init&lt;/code&gt;&lt;/a&gt; podemos automatizar el proceso de configuración tal y como lo hacen los proveedores de cloud público (AWS, Azure, Google Cloud&amp;hellip;)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalación de KVM en Ubuntu 20.04</title>
      <link>https://onthedock.github.io/post/200627-instalacion-de-kvm-en-ubuntu-20.04/</link>
      <pubDate>Sat, 27 Jun 2020 16:27:29 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/200627-instalacion-de-kvm-en-ubuntu-20.04/</guid>
      <description>&lt;p&gt;Después de convertir el equipo de laboratorio en mi equipo de escritorio, poco a poco lo estoy convirtiendo de nuevo en un &lt;strong&gt;equipo de laboratorio&lt;/strong&gt; :D&lt;/p&gt;
&lt;p&gt;Después del desagradable sabor de boca con &lt;a href=&#34;https://wiki.gnome.org/Apps/Boxes&#34;&gt;GNOME Boxes&lt;/a&gt; que me dejó mi &lt;a href=&#34;https://onthedock.github.io/post/200620-odiando-fedora-en-menos-de-1-hora/&#34;&gt;efímera prueba en Fedora&lt;/a&gt;, he recuperado el entorno basado en KVM (aunque no tuviera éxito con Proxmox VE).&lt;/p&gt;
&lt;p&gt;En esta entrada describo los pasos seguidos para instalar KVM en Ubuntu 20.04 con las notas que he ido tomando durante el proceso.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prevenir sustos al eliminar stacks de CloudFormation</title>
      <link>https://onthedock.github.io/post/200528-prevenir-sustos-al-eliminar-stacks/</link>
      <pubDate>Thu, 28 May 2020 19:54:41 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/200528-prevenir-sustos-al-eliminar-stacks/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Actualizado 24 Julio 2020.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Al eliminar un &lt;em&gt;stack&lt;/em&gt; de CloudFormation &lt;strong&gt;todos&lt;/strong&gt; los recursos creados por el &lt;em&gt;stack&lt;/em&gt; se eliminan automáticamente. Esto te puede provocar un buen susto cuando eliminas uno por error&amp;hellip;&lt;/p&gt;
&lt;p&gt;En esta entrada indico cómo prevenir esas situaciones a diferentes niveles: aplicando &lt;em&gt;stack policies&lt;/em&gt; a todo el &lt;em&gt;stack&lt;/em&gt; o de forma individual en algunos recursos con &lt;em&gt;DeletionPolicy&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalar OKD 3.11 en Centos 7 (Minimal)</title>
      <link>https://onthedock.github.io/post/200401-instalar-okd311-en-centos7/</link>
      <pubDate>Wed, 01 Apr 2020 18:51:15 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/200401-instalar-okd311-en-centos7/</guid>
      <description>&lt;p&gt;La instalación de &lt;a href=&#34;https://www.okd.io/&#34;&gt;OKD&lt;/a&gt;, la distribución &lt;em&gt;opensource&lt;/em&gt; de &lt;a href=&#34;https://www.openshift.com/&#34;&gt;OpenShift&lt;/a&gt; es compleja y tiene unos prerequisitos que, al menos en mi caso, me han echado un poco &lt;em&gt;pa&amp;rsquo;trás&lt;/em&gt; a la hora de instalarlo.&lt;/p&gt;
&lt;p&gt;Recientemente he encontrado una instalación basada completamente en contenedores que, aunque no es exactamente igual a la versión &lt;em&gt;estándard&lt;/em&gt;, permite familiarizarse con el producto, el despliegue de aplicaciones, etc&amp;hellip;&lt;/p&gt;
&lt;p&gt;En esta entrada indico cómo instalar OKD 3.11 sobre Centos 7 (Minimal).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalación de Linux en modo gráfico seguro</title>
      <link>https://onthedock.github.io/post/200221-nomodeset/</link>
      <pubDate>Sat, 21 Mar 2020 21:20:25 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/200221-nomodeset/</guid>
      <description>&lt;p&gt;Los &lt;em&gt;kernels&lt;/em&gt; de Linux modernos han movido la configuración de los modos de vídeo al &lt;em&gt;kernel&lt;/em&gt;. Algunas tarjetas gráficas no funcionan correctamente tras este cambio, por lo que el proceso de instalación de Linux falla de un modo u otro; en mi caso, el sistema se reinicia a los pocos segundos de empezar el proceso de arranque del sistema, aunque lo habitual es que la pantalla se quede &amp;ldquo;en blanco&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regenerar certificado SSL en Proxmox</title>
      <link>https://onthedock.github.io/post/200119-regenerar-certificado-ssl-proxmox/</link>
      <pubDate>Sun, 19 Jan 2020 11:01:05 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/200119-regenerar-certificado-ssl-proxmox/</guid>
      <description>&lt;p&gt;Hace relativamente poco que he cambiado de piso, lo que ha afectado a la &lt;em&gt;toopología&lt;/em&gt; de la red de casa, en particular, ha sido necesario cambiar la IP del equipo de laboratorio donde tengo instalado &lt;a href=&#34;https://www.proxmox.com/en/&#34;&gt;Proxmox VE&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Como el acceso a la consola web de Proxmox VE se realiza a través de https, los navegadores rechazaban la conexión al tratarse de un certificado inválido (emitido para una IP que no coincide con la actual) (además de la habitual alerta indicando que la entidad certificadora que firma el certificado no se reconoce).&lt;/p&gt;
&lt;p&gt;En esta entrada indico cómo regenerar el certificado SSL autofirmado por Proxmox VE.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Como enviar un proceso a segundo plano (y recuperarlo después)</title>
      <link>https://onthedock.github.io/post/191208-como-enviar-un-proceso-a-segundo-plano-y-recuperarlo-despues/</link>
      <pubDate>Sun, 08 Dec 2019 08:19:29 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/191208-como-enviar-un-proceso-a-segundo-plano-y-recuperarlo-despues/</guid>
      <description>&lt;p&gt;Cuando se lanza un comando en la terminal -en general-, hace lo que tiene que hacer y termina. Sin embargo, algunos procesos se ejecutan indefinidamente (hasta que el usuario los termina usando &lt;code&gt;Ctrl+C&lt;/code&gt;). En este caso, el terminal queda &lt;em&gt;bloqueado&lt;/em&gt;, en el sentido de que el usuario no puede lanzar nuevos comandos.&lt;/p&gt;
&lt;p&gt;En esta entrada indico las diferentes opciones que tienes para poder gestionar comandos en un terminal de Linux.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Configuración de awscli-login</title>
      <link>https://onthedock.github.io/post/190830-configuracion-de-awscli-login/</link>
      <pubDate>Fri, 30 Aug 2019 23:07:34 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190830-configuracion-de-awscli-login/</guid>
      <description>&lt;p&gt;Uno de los problemas de usar usuarios IAM con acceso programático a los recursos en AWS es la seguridad de la &lt;em&gt;secret key&lt;/em&gt; (incluso habilitando la seguridad con varios factores de autenticación (MFA)).&lt;/p&gt;
&lt;p&gt;Cuando un trabajador deja de estar vinculado a la empresa, existen procesos que se encargan de &lt;em&gt;decomisionar&lt;/em&gt; los elementos asociados al ex-trabajador; en particular, se elimina el acceso a los sistemas a los que tuviera acceso mediante la desactivación de las cuentas del usuario.&lt;/p&gt;
&lt;p&gt;El problema es que los usuarios IAM tienen claves de acceso programático que permiten el acceso a los recursos de manera independiente a los sistemas de gestión de identidad corporativa (generalmente un LDAP) sin necesidad de estar conectados a la red de la empresa.&lt;/p&gt;
&lt;p&gt;Aunque la solución más directa parece la modificación del proceso de baja para incluir anulación de los usuarios IAM, lo ideal es conseguir acceso programático a AWS con &lt;strong&gt;credenciales federadas&lt;/strong&gt;, es decir, centralizando la autenticación en el sistema de gestión de identidades de la empresa.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Nuevo usuario IAM en AWS</title>
      <link>https://onthedock.github.io/post/190827-nuevo-usuario-iam-en-aws/</link>
      <pubDate>Tue, 27 Aug 2019 19:52:01 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190827-nuevo-usuario-iam-en-aws/</guid>
      <description>&lt;p&gt;Al final de la &lt;a href=&#34;https://onthedock.github.io/post/190820-instala-aws-cli/&#34;&gt;entrada anterior&lt;/a&gt; indicaba que para empezar a usar tu cuenta de AWS necesitas un usuario.&lt;/p&gt;
&lt;p&gt;A continuación comento cómo crear un usuario IAM.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instala la herramienta de línea de comandos de AWS</title>
      <link>https://onthedock.github.io/post/190820-instala-aws-cli/</link>
      <pubDate>Tue, 20 Aug 2019 19:48:20 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190820-instala-aws-cli/</guid>
      <description>&lt;p&gt;Los primeros pasos en el cloud de Amazon se dan a través de la consola web de AWS.&lt;/p&gt;
&lt;p&gt;Sin embargo, la verdadera potencia de AWS es que todas las acciones que se realizan a través de la consola se pueden ejecutar desde la línea de comandos.&lt;/p&gt;
&lt;p&gt;Y si pueden ejecutarse desde la línea de comandos, pueden &lt;strong&gt;automatizarse&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Ahí es donde empieza lo interesante&amp;hellip;&lt;/p&gt;
&lt;p&gt;Pero antes necesitamos instalar &lt;code&gt;aws-cli&lt;/code&gt; (o simplemente &lt;code&gt;aws&lt;/code&gt;), la herramienta de línea de comandos para interaccionar con la API de AWS.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pivotando el contenido del blog</title>
      <link>https://onthedock.github.io/post/190818-pivotando-el-contenido-del-blog/</link>
      <pubDate>Sun, 18 Aug 2019 18:28:01 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190818-pivotando-el-contenido-del-blog/</guid>
      <description>&lt;p&gt;En las metodologías ágiles, se habla de &lt;em&gt;pivotar&lt;/em&gt; cuando se cambia el modelo de negocio de una empresa -normalmente una &lt;em&gt;start up&lt;/em&gt;- para adaptarse a las necesidades de los usuarios y potenciales clientes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instance Scheduler Cross Account</title>
      <link>https://onthedock.github.io/post/190529-instance-scheduler-cross-account/</link>
      <pubDate>Wed, 29 May 2019 19:47:29 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190529-instance-scheduler-cross-account/</guid>
      <description>&lt;p&gt;En la entrada &lt;a href=&#34;https://onthedock.github.io/post/190526-aws-instance-scheduler/&#34;&gt;AWS Instance Scheduler&lt;/a&gt; indicaba cómo configurar AWS Instance Scheduler en una cuenta. Sin embargo, una de las capacidades más interesantes de esta solución de Amazon es la posibilidad de programar el encendido (y/o apagado) de instancias en diferentes cuentas.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Session Manager como herramienta de control de acceso a instancias EC2 en AWS</title>
      <link>https://onthedock.github.io/post/190527-aws-session-manager/</link>
      <pubDate>Mon, 27 May 2019 19:33:13 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190527-aws-session-manager/</guid>
      <description>&lt;p&gt;Uno de los problemas habituales en un entorno cloud es cómo gestionar el acceso a las instancias del cloud de forma controlada y segura. Session Manager es un servicio de AWS que resuelve este problema y que además es gratuito.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AWS Instance Scheduler</title>
      <link>https://onthedock.github.io/post/190526-aws-instance-scheduler/</link>
      <pubDate>Sun, 26 May 2019 14:07:10 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190526-aws-instance-scheduler/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/solutions/latest/instance-scheduler/welcome.html&#34;&gt;AWS Instance Scheduler&lt;/a&gt; permite gestionar el arranque y parada automáticos de instancias EC2 y bases de datos del servicio AWS RDS de forma programada.
Esta es una de las formas más sencillas de ahorrar en el uso de estos servicios de AWS: apagándolos cuando no se necesitan (por ejemplo en entornos de desarrollo o de test).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Error al actualizar el sistema</title>
      <link>https://onthedock.github.io/post/190519-error-al-actualizar-el-sistema/</link>
      <pubDate>Sun, 19 May 2019 18:11:23 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190519-error-al-actualizar-el-sistema/</guid>
      <description>&lt;p&gt;Después de resolver el &lt;a href=&#34;https://onthedock.github.io/post/190519-iniciar-dnsmasq-durante-el-inicio-del-sistema/&#34;&gt;problema con el DNS&lt;/a&gt; en el equipo de laboratorio tenía varias actualizaciones pendientes de instalar.&lt;/p&gt;
&lt;p&gt;Sin embargo, una de las actualizaciones ha fallado por no tener bien resueltas las depedencias:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Iniciar dnsmasq durante el inicio del sistema</title>
      <link>https://onthedock.github.io/post/190519-iniciar-dnsmasq-durante-el-inicio-del-sistema/</link>
      <pubDate>Sun, 19 May 2019 08:42:05 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190519-iniciar-dnsmasq-durante-el-inicio-del-sistema/</guid>
      <description>&lt;p&gt;dnsmasq es un servidor DNS y por tanto debería estar siempre arrancado, para responder  a las peticiones de resolución de nombres precedentes del resto de máquinas.&lt;/p&gt;
&lt;p&gt;La instalación en Alpine Linux no configura el servicio de dnsmasq para iniciar durante el arranque del sistema, por lo que debe iniciarse manualmente.&lt;/p&gt;
&lt;p&gt;Esta no es la configuración que queremos, así que vamos a corregirla.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bug en Firefox Corregido</title>
      <link>https://onthedock.github.io/post/190506-bug-en-firefox-corregido/</link>
      <pubDate>Mon, 06 May 2019 20:41:25 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190506-bug-en-firefox-corregido/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://onthedock.github.io/post/190505-fallo-de-las-extensiones-en-firefox/&#34;&gt;Ayer&lt;/a&gt; comentaba el &lt;em&gt;bug&lt;/em&gt; en Firefox que provocaba que no se pudiera validar la firma de las extensiones y que hacía que todas se desactivaran.&lt;/p&gt;
&lt;p&gt;Esto me hizo darme de bruces con la &lt;strong&gt;realidad&lt;/strong&gt; de internet, un mundo plagado de anuncios totalmente desconsiderados.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fallo en las extensiones de Firefox</title>
      <link>https://onthedock.github.io/post/190505-fallo-de-las-extensiones-en-firefox/</link>
      <pubDate>Sun, 05 May 2019 18:50:31 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190505-fallo-de-las-extensiones-en-firefox/</guid>
      <description>&lt;p&gt;Ayer noté que veía muchos anuncios en las páginas que suelo visitar. Revisando las opciones de Firefox, observé que se había deshabilitado la extensión de bloqueo de anuncios &amp;ldquo;al no poder &lt;em&gt;verificarse&lt;/em&gt;&amp;quot;: &lt;code&gt;One or more installed add-ons cannot be verified and have been disabled&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Imaginé algún cambio en la normativa de extensiones de Firefox -similar a lo que pasó con Safari hace un tiempo- y no le di mayor importancia.&lt;/p&gt;
&lt;p&gt;Me dirigí a la &amp;ldquo;tienda&amp;rdquo; oficial de Mozilla para descargar alguna extensión alternativa y pronto descubrí que el problema era mucho peor de lo que había imaginado.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cómo habilitar qemu-guest-agent en Alpine Linux</title>
      <link>https://onthedock.github.io/post/190429-como-habilitar-qemu-guest-agent-en-alpine/</link>
      <pubDate>Mon, 29 Apr 2019 19:50:54 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190429-como-habilitar-qemu-guest-agent-en-alpine/</guid>
      <description>&lt;p&gt;&lt;code&gt;qemu-guest-agent&lt;/code&gt; es un agente que puede instalarse en los sistemas invitados en Proxmox VE que permite obtener información sobre los sistemas corriendo en máquinas virtuales.
Uno de esos datos es la IP del sistema.&lt;/p&gt;
&lt;p&gt;Sin embargo, para los sistemas Alpine Linux, el servicio no arranca automáticamente.
Se puede habilitar de forma manual, pero lo ideal es que el &lt;em&gt;demonio&lt;/em&gt; arranque automáticamente durante el arranque.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automatizando la gestion de máquinas virtuales con Ansible en Proxmox VE (spoiler, no me ha funcionado)</title>
      <link>https://onthedock.github.io/post/190428-automatizando-la-gestion-de-vms-con-ansible-en-proxmox/</link>
      <pubDate>Sun, 28 Apr 2019 20:11:52 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190428-automatizando-la-gestion-de-vms-con-ansible-en-proxmox/</guid>
      <description>&lt;p&gt;Sigo dando pasos en el &lt;a href=&#34;https://onthedock.github.io/post/181124-roadmap/&#34;&gt;&lt;em&gt;roadmap&lt;/em&gt; que me marqué ya hace un tiempo&lt;/a&gt;, aunque mucho más lentamente de lo que había previsto.&lt;/p&gt;
&lt;p&gt;Después de decidir montar todo el laboratorio sobre KVM -y conseguirlo-, a nivel operativo no me resultaba cómodo.
Podía usar VirtManager (una solución gráfica), pero que sólo tenía instalada en un desktop con Linux que no suelo usar habitualmente, o hacer SSH contra el equipo de laboratorio y usar la línea de comandos para generar la máquina desde cero&amp;hellip;&lt;/p&gt;
&lt;p&gt;Al final, manteniéndome fiel al &lt;em&gt;objetivo final&lt;/em&gt; de automatizar la solución, decidí usar Proxmox VE (que usa Debian y KVM &amp;ldquo;bajo el capó&amp;rdquo;) y que además se integra con Ansible.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalación de Ansible en Debian 9</title>
      <link>https://onthedock.github.io/post/190419-instalacion-de-ansible-en-debian9/</link>
      <pubDate>Fri, 19 Apr 2019 17:04:12 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/190419-instalacion-de-ansible-en-debian9/</guid>
      <description>&lt;p&gt;Ansible permite automatizar la configuración de máquinas. Curiosamente, aunque he hablado de &lt;a href=&#34;https://onthedock.github.io/tags/ansible/&#34;&gt;Ansible&lt;/a&gt; en otras ocasiones, no había dedicado ninguna entrada al proceso de instalación y configuración.&lt;/p&gt;
&lt;p&gt;Vamos a corregir esta situación ;)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cómo clonar máquinas virtuales y usar virt-sysprep en KVM</title>
      <link>https://onthedock.github.io/post/190213-como-clonar-vms-y-usar-sysprep-en-kvm/</link>
      <pubDate>Wed, 13 Feb 2019 20:57:24 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/190213-como-clonar-vms-y-usar-sysprep-en-kvm/</guid>
      <description>&lt;p&gt;En la entrada anterior hemos visto cómo crear y clonar discos. Si el disco clonado contiene el sistema operativo de una máquina virtual, el clon continene identificadores que deberían ser únicos (como el &lt;em&gt;machine ID&lt;/em&gt;, direcciones MAC, claves SSH de &lt;em&gt;host&lt;/em&gt;, etc).&lt;/p&gt;
&lt;p&gt;Podemos usar &lt;code&gt;virt-sysprep&lt;/code&gt; para eliminar todos estos identificadores únicos.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cómo gestionar discos en KVM</title>
      <link>https://onthedock.github.io/post/190211-como-gestionar-discos-en-kvm/</link>
      <pubDate>Mon, 11 Feb 2019 19:31:08 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/190211-como-gestionar-discos-en-kvm/</guid>
      <description>&lt;p&gt;Una vez creados los &lt;em&gt;storage pools&lt;/em&gt; llega el momento de empezar a llenarlos con discos.&lt;/p&gt;
&lt;p&gt;En la &lt;a href=&#34;https://onthedock.github.io/post/190209-como-crear-un-storage-pool-en-kvm/&#34;&gt;entrada anterior&lt;/a&gt; hemos visto cómo añadir una imagen ISO al &lt;em&gt;pool&lt;/em&gt; que hemos creado para los medios de instalación.&lt;/p&gt;
&lt;p&gt;Ahora vamos a crear discos para las máquinas virtuales.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cómo crear un storage pool en KVM</title>
      <link>https://onthedock.github.io/post/190209-como-crear-un-storage-pool-en-kvm/</link>
      <pubDate>Sat, 09 Feb 2019 19:07:08 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/190209-como-crear-un-storage-pool-en-kvm/</guid>
      <description>&lt;p&gt;En KVM existe el concepto de &lt;em&gt;storage pool&lt;/em&gt;, que como indica su nombre, es un recurso de almacenamiento.&lt;/p&gt;
&lt;p&gt;En mi caso, todo el almacenamiento es local, por lo que voy a examinar el &lt;em&gt;pool&lt;/em&gt; existente y a continuación crearé un nuevo &lt;em&gt;storage pool&lt;/em&gt; para guardar las ISOs de instalación de los diversos sistemas operativos que utilice.&lt;/p&gt;
&lt;p&gt;Al disponer únicamente del disco local como espacio de almacenamiento la creación de &lt;em&gt;storage pools&lt;/em&gt; adicionales sirve para separar los discos de las VMs (que dejaré en el &lt;em&gt;pool&lt;/em&gt; &lt;strong&gt;default&lt;/strong&gt;) de las ISOs y de paso, aprender cómo funcionan los &lt;em&gt;storage pool&lt;/em&gt; en KVM ;)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cómo habilitar virtualización anidada en KVM</title>
      <link>https://onthedock.github.io/post/190205-como-habilitar-virtualizacion-anidada-en-kvm/</link>
      <pubDate>Tue, 05 Feb 2019 22:14:15 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/190205-como-habilitar-virtualizacion-anidada-en-kvm/</guid>
      <description>&lt;p&gt;La virtualización anidada permite ejecutar una máquina virtual &lt;em&gt;dentro&lt;/em&gt; de otra máquina virtual aprovechando las posibilidades de aceleración por hardware que proporciona el sistema anfitrión.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>KVM en Ubuntu Server</title>
      <link>https://onthedock.github.io/post/190124-kvm-en-ubuntu-server/</link>
      <pubDate>Thu, 24 Jan 2019 20:11:23 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/190124-kvm-en-ubuntu-server/</guid>
      <description>&lt;p&gt;KVM es un módulo de virtualización que permite al kernel de Linux funcionar como hipervisor. Al formar parte del kernel de Linux, no requiere un entorno de escritorio. Esto permite reducir el &lt;em&gt;peso extra&lt;/em&gt; del sistema, pero también supone un reto a la hora de gestionar las máquinas virtuales.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Generando un machine-id único</title>
      <link>https://onthedock.github.io/post/180810-generando-un-machine-id-unico/</link>
      <pubDate>Fri, 10 Aug 2018 18:10:27 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180810-generando-un-machine-id-unico/</guid>
      <description>&lt;p&gt;En la entrada &lt;a href=&#34;https://onthedock.github.io/post/180610-pods-en-estado-creatingcontainer-en-k8s/&#34;&gt;Pods en estado creatingContainer en K8s&lt;/a&gt; describía el problema surgido al crear un clúster de Kubernetes usando Vagrant. Al partir de la misma imagen, todas las máquinas del clúster tienen el mismo &lt;code&gt;machine-id&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;El &lt;code&gt;machine-id&lt;/code&gt; debe ser único, como se describe en los &lt;a href=&#34;https://kubernetes.io/docs/setup/independent/install-kubeadm/#verify-the-mac-address-and-product-uuid-are-unique-for-every-node&#34;&gt;requerimientos de Kubernetes&lt;/a&gt;; si no lo es, se producen problemas como el descrito.&lt;/p&gt;
&lt;p&gt;En esta entrada analizo con más detalle cómo se crea el &lt;em&gt;machine-id&lt;/em&gt; y cómo generar uno nuevo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gitea: la versión mejorada de Gogs</title>
      <link>https://onthedock.github.io/post/180713-gitea-la-version-mejorada-de-gogs/</link>
      <pubDate>Fri, 13 Jul 2018 20:04:36 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180713-gitea-la-version-mejorada-de-gogs/</guid>
      <description>&lt;p&gt;Gogs es un servidor web de repositorios Git (a lo GitHub). He hablado otras veces de lo sencillo que es montarlo usando Docker, de manera independiente (&lt;a href=&#34;https://onthedock.github.io/post/171106-gogs-como-crear-tu-propio-servicio-de-hospedaje-de-repos-git/&#34;&gt;usando SQLite&lt;/a&gt; como base de datos o &lt;a href=&#34;https://onthedock.github.io/post/180520-pipeline-gogs-el-repositorio-de-codigo/&#34;&gt;con MySQL&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;A través de este artículo &lt;a href=&#34;https://www.cyberciti.biz/open-source/github-alternatives-open-source-seflt-hosted/&#34;&gt;6 Github alternatives that are open source and self-hosted&lt;/a&gt; descubrí hace unos días &lt;a href=&#34;https://gitea.io&#34;&gt;Gitea&lt;/a&gt; y a continuación te explico porqué creo que es todavía mejor que Gogs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pods encallados en estado CreatingContainer en Kubernetes con nodos creados usando Vagrant</title>
      <link>https://onthedock.github.io/post/180610-pods-en-estado-creatingcontainer-en-k8s/</link>
      <pubDate>Sun, 10 Jun 2018 20:54:27 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180610-pods-en-estado-creatingcontainer-en-k8s/</guid>
      <description>&lt;p&gt;Una de las maneras más sencillas de crear un entorno de desarrollo para Kubernetes es usando Vagrant y Ansible.&lt;/p&gt;
&lt;p&gt;En el &lt;code&gt;Vagrantfile&lt;/code&gt; definimos un conjunto de tres máquinas, llamadas &lt;code&gt;node1&lt;/code&gt;, &lt;code&gt;node2&lt;/code&gt; y &lt;code&gt;node3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Una vez las máquinas están levantadas, desde el servidor de Ansible uso &lt;code&gt;ssh-copy-id&lt;/code&gt; para habilitar el &lt;em&gt;login&lt;/em&gt; sin password de Ansible en los nodos del clúster.&lt;/p&gt;
&lt;p&gt;A partir de aquí, tanto la instalación de los prerequisitos como la inicialización del clúster funcionan sin problemas; sin embargo, al intentar desplegar una aplicación, los &lt;em&gt;pods&lt;/em&gt; se quedan en el estado &lt;em&gt;CreatingContainer&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pipeline - Análisis de código con Sonarqube</title>
      <link>https://onthedock.github.io/post/180522-pipeline-analisis-de-codigo-con-sonarqube/</link>
      <pubDate>Wed, 23 May 2018 12:12:06 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180522-pipeline-analisis-de-codigo-con-sonarqube/</guid>
      <description>&lt;p&gt;En entradas anteriores hemos &lt;a href=&#34;https://onthedock.github.io/post/180521-subiendo-el-codigo-a-gogs/&#34;&gt;subido el código de la aplicación al repositorio en Gogs&lt;/a&gt; y hemos &lt;a href=&#34;https://onthedock.github.io/post/180521-pipeline-instalacion-de-sonarqube/&#34;&gt;instalado SonarQube&lt;/a&gt; y &lt;a href=&#34;https://onthedock.github.io/post/180520-pipeline-instalacion-y-actualizacion-de-jenkins/&#34;&gt;Jenkins&lt;/a&gt;. Ahora, vamos a configurar Jenkins para que analice el código de la aplicación y detectar fallos incluso antes de compilar la aplicación.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Update 2022-01-06&lt;/strong&gt; He actualizado los enlaces externos hacia la documentación de SonarQube. Por favor, revisa la documentación oficial actualizada ya que este artículo se escribió para una versión anterior de SonarQube.&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>De Docker Stats a un fichero CSV</title>
      <link>https://onthedock.github.io/post/180522-docker-stats/</link>
      <pubDate>Tue, 22 May 2018 23:02:24 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180522-docker-stats/</guid>
      <description>&lt;p&gt;Docker proporciona el comando &lt;code&gt;docker stats&lt;/code&gt; para monitorizar el uso de CPU, memoria, etc de los contenedores en ejecución:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pipeline - Troubleshooting del arranque del contenedor con Sonarqube</title>
      <link>https://onthedock.github.io/post/180521-pipeline-troubleshooting-del-arranque-del-contenedor-con-sonarqube/</link>
      <pubDate>Mon, 21 May 2018 12:37:10 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180521-pipeline-troubleshooting-del-arranque-del-contenedor-con-sonarqube/</guid>
      <description>&lt;p&gt;En las guías y tutoriales en internet siempre funciona todo sin ningún fallo. Sin embargo, lo más habitual es que encontremos problemas en los primeros intentos de poner en marcha una aplicación.&lt;/p&gt;
&lt;p&gt;Personalmente, creo que el aprendizaje es un proceso de ensayo y error, por lo que se aprende solucionando los errores que nos encontramos.&lt;/p&gt;
&lt;p&gt;Con esa idea en mente, también intento documentar los fallos que cometo. A continuación tienes el registro de las acciones que realicé para solucionar los problemas encontrados en el arranque de SonarQube.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pipeline - Instalación de Sonarqube</title>
      <link>https://onthedock.github.io/post/180521-pipeline-instalacion-de-sonarqube/</link>
      <pubDate>Mon, 21 May 2018 12:19:43 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180521-pipeline-instalacion-de-sonarqube/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.sonarqube.org/&#34;&gt;SonarQube&lt;/a&gt; es una herramienta de análisis continuo de código.&lt;/p&gt;
&lt;p&gt;La versión &lt;em&gt;open source&lt;/em&gt; ofrece soporte para 20 lenguajes de programación, mientras que la versión comercial amplía el número de &lt;em&gt;analizadores&lt;/em&gt;. También hay &lt;em&gt;analizadores&lt;/em&gt; creados por la comunidad.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pipeline - Creacion del job en Jenkins</title>
      <link>https://onthedock.github.io/post/180521-pipeline-creacion-del-job-en-jenkins/</link>
      <pubDate>Mon, 21 May 2018 12:03:50 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180521-pipeline-creacion-del-job-en-jenkins/</guid>
      <description>&lt;p&gt;Una vez tenemos código en el repositorio de &lt;a href=&#34;https://onthedock.github.io/post/180521-subiendo-el-codigo-a-gogs/&#34;&gt;Gogs&lt;/a&gt;, para poder avanzar tenemos que definir y configurar el &lt;em&gt;pipeline&lt;/em&gt; en Jenkins.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pipeline - Subiendo el código a Gogs</title>
      <link>https://onthedock.github.io/post/180521-subiendo-el-codigo-a-gogs/</link>
      <pubDate>Mon, 21 May 2018 09:03:13 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180521-subiendo-el-codigo-a-gogs/</guid>
      <description>&lt;p&gt;Ya hemos instalado &lt;a href=&#34;https://onthedock.github.io/post/180520-pipeline-gogs-el-repositorio-de-codigo/&#34;&gt;Gogs&lt;/a&gt; y &lt;a href=&#34;https://onthedock.github.io/post/180520-pipeline-instalacion-y-actualizacion-de-jenkins/&#34;&gt;Jenkins&lt;/a&gt; en nuestro sistema; ahora es el momento de empezar a subir código y ver qué podemos hacer con él.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pipeline - Instalacion y actualizacion de Jenkins</title>
      <link>https://onthedock.github.io/post/180520-pipeline-instalacion-y-actualizacion-de-jenkins/</link>
      <pubDate>Sun, 20 May 2018 07:43:06 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180520-pipeline-instalacion-y-actualizacion-de-jenkins/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://jenkins.io/&#34;&gt;Jenkins&lt;/a&gt; es un servidor de &lt;em&gt;automatización&lt;/em&gt; de código abierto escrito en Java. Es una herramienta clave en el proceso de integración continua y un facilitador de cara a realizar despliegues continuos.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pipeline: Gogs - El repositorio de código</title>
      <link>https://onthedock.github.io/post/180520-pipeline-gogs-el-repositorio-de-codigo/</link>
      <pubDate>Sun, 20 May 2018 07:30:49 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180520-pipeline-gogs-el-repositorio-de-codigo/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://gogs.io&#34;&gt;Gogs&lt;/a&gt; es un servidor de Git escrito en Go. Proporciona un interfaz web similar a GitHub.&lt;/p&gt;
&lt;p&gt;En esta entrada se describe cómo lanzar los contenedores necesarios para tener una instalación funcional de Gogs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pipeline: Aplicaciones auxiliares</title>
      <link>https://onthedock.github.io/post/180520-pipeline-aplicaciones-auxiliares/</link>
      <pubDate>Sun, 20 May 2018 07:08:04 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180520-pipeline-aplicaciones-auxiliares/</guid>
      <description>&lt;p&gt;Como indicaba en el entrada &lt;a href=&#34;https://onthedock.github.io/post/180518-integracion-continua-con-jenkins-y-docker/&#34;&gt;que abría esta serie&lt;/a&gt;, además de las aplicaciones que forman parte del &lt;em&gt;pipeline&lt;/em&gt;, uso algunas aplicaciones auxiliares.&lt;/p&gt;
&lt;p&gt;Estas aplicaciones son &lt;em&gt;MailDev&lt;/em&gt; y &lt;em&gt;Portainer&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pipeline: Consideraciones Generales</title>
      <link>https://onthedock.github.io/post/180519-pipeline-consideraciones-generales/</link>
      <pubDate>Sat, 19 May 2018 20:12:47 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180519-pipeline-consideraciones-generales/</guid>
      <description>&lt;p&gt;El principal objetivo de esta serie de artículos es aprender a construir un &lt;em&gt;pipeline&lt;/em&gt; siguiendo, en la medida de lo posible, las mejores prácticas de cada producto.&lt;/p&gt;
&lt;p&gt;En esta guía, se muestran los pasos a seguir de principio a fin sin que falle nada; sin embargo, el proceso real es &lt;strong&gt;muy diferente&lt;/strong&gt;, con multitud de errores a lo largo del camino.&lt;/p&gt;
&lt;p&gt;En esta entrada quiero exponer algunos de los cambios que he realizado, a nivel de diseño de la arquitectura durante la creación del &lt;em&gt;pipeline&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ejecutar script al hacer login en el sistema</title>
      <link>https://onthedock.github.io/post/180517-ejecutar-script-al-hacer-login/</link>
      <pubDate>Thu, 17 May 2018 08:00:35 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/180517-ejecutar-script-al-hacer-login/</guid>
      <description>&lt;p&gt;Al hacer login en un sistema Ubuntu, se suele presentar información acerca de los paquetes disponibles para actualización y otra información relevante.&lt;/p&gt;
&lt;p&gt;En esta entrada indico cómo conseguir el mismo resultado mostrando la información que te interesa sobre el sistema.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cómo proteger el acceso remoto a Docker</title>
      <link>https://onthedock.github.io/post/180318-como-proteger-el-acceso-remoto-a-docker/</link>
      <pubDate>Sun, 18 Mar 2018 11:33:24 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/180318-como-proteger-el-acceso-remoto-a-docker/</guid>
      <description>&lt;p&gt;En la entrada  &lt;a href=&#34;https://onthedock.github.io/post/180317-portainer/&#34;&gt;Portainer: gestión de servidores Docker&lt;/a&gt; comentaba la necesidad de habilitar el acceso remoto al API de Docker &lt;strong&gt;de manera segura&lt;/strong&gt;, apuntando a la documentación oficial de Docker sobre cómo realizar esta configuración.&lt;/p&gt;
&lt;p&gt;En esta entrada indico cómo proteger el acceso remoto a un servidor de Docker a través de la API, siguiendo las indicaciones de la documentación oficial en &lt;a href=&#34;https://docs.docker.com/engine/security/https/&#34;&gt;Protect the Docker daemon socket&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Portainer: gestión de servidores Docker</title>
      <link>https://onthedock.github.io/post/180317-portainer/</link>
      <pubDate>Sat, 17 Mar 2018 21:44:47 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/180317-portainer/</guid>
      <description>&lt;p&gt;En una entrada anterior expliqué mi primera toma de contacto con Portainer y cómo usar &lt;a href=&#34;https://onthedock.github.io/post/170429-portainer-para-gestionar-tus-contenedores-en-docker/&#34;&gt;Portainer para gestionar tus contenedores en Docker&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;La herramienta -y la &lt;a href=&#34;https://portainer.readthedocs.io/en/stable/&#34;&gt;documentación&lt;/a&gt;- ha mejorado durante este tiempo, por lo que ahora el proceso es todavía más sencillo y Portainer más potente.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Ignorar el DNS asignado por el servidor DHCP</title>
      <link>https://onthedock.github.io/post/171208-ignorar-el-dns-asignado-por-el-servidor-dhcp/</link>
      <pubDate>Fri, 08 Dec 2017 08:39:09 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/171208-ignorar-el-dns-asignado-por-el-servidor-dhcp/</guid>
      <description>&lt;p&gt;Después de instalar y configurar &lt;code&gt;dnsmasq&lt;/code&gt;, quiero hacer que éste sea el DNS usado por defecto. Como el servidor DHCP proporciona, además de la IP los servidores DNS, las máquinas virtuales en el equipo de laboratorio no son capaces de resolver los nombres del resto de máquinas del definidos en &lt;code&gt;dnsmasq&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dime qué opinas</title>
      <link>https://onthedock.github.io/post/171206-dime-que-opinas/</link>
      <pubDate>Wed, 06 Dec 2017 08:22:03 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/171206-dime-que-opinas/</guid>
      <description>El objetivo del blog es ir anotando los problemas -y las soluciones- que encuentro relacionados con la aventura de aprender sobre el mundillo de los contenedores. Nuestro escenario particular es único, pero casi siempre los problemas que encontramos ya los ha solucionado antes alguien que sabe mucho más que nosotros. Encontrar la solución correcta, o la que se ajusta a nuestro caso es complicado. A veces la solución encontrada sirve para poder tirar un poco más del hilo y obtener más información sobre la causa del problema&amp;hellip;</description>
    </item>
    
    <item>
      <title>Crea un registro local para tus imágenes</title>
      <link>https://onthedock.github.io/post/171202-crea-un-registro-local-para-tus-imagenes/</link>
      <pubDate>Sat, 02 Dec 2017 13:48:17 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/171202-crea-un-registro-local-para-tus-imagenes/</guid>
      <description>&lt;p&gt;El registro por defecto donde almacenar y compartir las imágenes Docker es &lt;a href=&#34;https://hub.docker.com&#34;&gt;Docker Hub&lt;/a&gt;. Desde un punto de vista empresarial, descargar imágenes desde un registro público supone un riesgo de seguridad.&lt;/p&gt;
&lt;p&gt;En esta entrada indico cómo lanzar el registro oficial de Docker en nuestra infraestructura. Una vez en marcha, veremos cómo almacenar las imágenes en el registro local y cómo lanzar contenedores usando las imágenes desde nuestro registro.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gogs No Arranca en la Raspberry Pi después de la configuración inicial</title>
      <link>https://onthedock.github.io/post/171118-gogs-no-arranca-en-rpi/</link>
      <pubDate>Sat, 18 Nov 2017 22:34:59 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/171118-gogs-no-arranca-en-rpi/</guid>
      <description>&lt;p&gt;En la entrada &lt;a href=&#34;https://onthedock.github.io/post/171106-gogs-como-crear-tu-propio-servicio-de-hospedaje-de-repos-git/&#34;&gt;Gogs - Cómo crear tu propio servicio de hospedaje de repositorios Git&lt;/a&gt; describía cómo montar un servicio como GitHub usando Gogs.&lt;/p&gt;
&lt;p&gt;Hoy he intentado montar lo mismo sobre la Raspberry Pi aprovechando que Gogs ofrece una imagen específica: &lt;a href=&#34;https://hub.docker.com/r/gogs/gogs-rpi/&#34;&gt;gogs/gogs-rpi&lt;/a&gt;,&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Single node cluster en la RPi3</title>
      <link>https://onthedock.github.io/post/171111-snc-en-rpi3/</link>
      <pubDate>Sat, 11 Nov 2017 12:08:36 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/171111-snc-en-rpi3/</guid>
      <description>&lt;p&gt;En la entrada anterior &lt;a href=&#34;https://onthedock.github.io/post/171104-apiserver-detenido/&#34;&gt;API server detenido: The connection to the server was refused&lt;/a&gt; encontré problemas con la tarjeta microSD que sirve de almacenamiento para el nodo master del clúster de Kubernetes.&lt;/p&gt;
&lt;p&gt;La solución al problema pasaba por realizar un análisis de la tarjeta para repararla. Sin embargo, al intentarlo, no ha habido manera de formatear y reinstalar HypriotOS sobre la tarjeta.&lt;/p&gt;
&lt;p&gt;El fallo de la tarjeta de memoria ha sido la gota final que me ha hecho abandonar el clúster multinodo en las Raspberry Pi (de momento). Así que he decidido instalar un clúster de un solo nodo en una de las Raspberri Pi 3.&lt;/p&gt;
&lt;p&gt;En este artículo sigo las instrucciones oficiales para construir un clúster de Kubernetes usando &lt;em&gt;kubeadm&lt;/em&gt;: &lt;a href=&#34;https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/&#34;&gt;Using kubeadm to Create a Cluster&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gogs - Cómo crear tu propio servicio de hospedaje de repositorios Git</title>
      <link>https://onthedock.github.io/post/171106-gogs-como-crear-tu-propio-servicio-de-hospedaje-de-repos-git/</link>
      <pubDate>Mon, 06 Nov 2017 22:11:26 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/171106-gogs-como-crear-tu-propio-servicio-de-hospedaje-de-repos-git/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://gogs.io/&#34;&gt;Gogs&lt;/a&gt; es la manera más sencilla, rápida y menos dolorosa de poner en marcha tu propio servicio de Git en tu infraestructura, tu propio &lt;em&gt;Github&lt;/em&gt;, para entendernos. Gogs proporciona un entorno web que permite gestionar los respositorios Git desde el navegador, el acceso que tienen los usuarios, gestionar &lt;em&gt;issues&lt;/em&gt; y &lt;em&gt;pull requests&lt;/em&gt; e incluso crear un wiki para documentar el proyecto.&lt;/p&gt;
&lt;p&gt;Es 100% código abierto, está escrito en Go y es &lt;em&gt;muy ligero&lt;/em&gt; (incluso puede correr en una Raspberry Pi).&lt;/p&gt;
&lt;p&gt;En este artículo te indico cómo confirgurarlo lanzándolo desde un contenedor sobre Docker.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>API server detenido: The connection to the server was refused</title>
      <link>https://onthedock.github.io/post/171104-apiserver-detenido/</link>
      <pubDate>Sat, 04 Nov 2017 21:58:52 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/171104-apiserver-detenido/</guid>
      <description>&lt;p&gt;Hoy, al intentar lanzar un comando con &lt;code&gt;kubectl&lt;/code&gt;, he obtenido el típico mensaje indicando que no se puede conectar con el servidor. El problema está en el servidor de API, que es el que actua como intermediario entre el usuario y Kubernetes. Últimamente he encontrado el mismo error y lo he solucionado reiniciando el nodo &lt;em&gt;master&lt;/em&gt; del clúster. Pero hoy he investigado un poco&amp;hellip; Y lo que he encontrado no me ha gustado demasiado.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Trucos para para línea de comandos</title>
      <link>https://onthedock.github.io/post/171002-trucos-para-la-linea-de-comandos/</link>
      <pubDate>Mon, 02 Oct 2017 20:44:00 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/171002-trucos-para-la-linea-de-comandos/</guid>
      <description>&lt;p&gt;Últimamente paso mucho tiempo en la línea de comando, por lo que aprender algunos &lt;em&gt;trucos&lt;/em&gt; en forma de combinaciones de teclas, etc, que me ayuden a ser mucho más ágil.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cómo arrancar contenedores durante el inicio del sistema</title>
      <link>https://onthedock.github.io/post/170920-autoarranque-de-contenedores/</link>
      <pubDate>Wed, 20 Sep 2017 22:09:46 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170920-autoarranque-de-contenedores/</guid>
      <description>&lt;p&gt;Una de las desventajas de Docker respecto a Kubernetes, es que en caso de fallo del nodo donde corren los contenedores, éstos no arrancan automáticamente cuando el nodo se recupera. El caso más sencillo es cuando hay que apagar/reiniciar el nodo por algún motivo.&lt;/p&gt;
&lt;p&gt;En mi caso, el &lt;em&gt;motivo de fallo&lt;/em&gt; del nodo ha sido que lo he apagado durante las vacaciones ;)&lt;/p&gt;
&lt;p&gt;De todas formas, he decidido configurar los contenedores de forma que se inicien automáticamente con el arranque del sistema. En este artículo te explico cómo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Probando Minio</title>
      <link>https://onthedock.github.io/post/170820-probando-minio/</link>
      <pubDate>Sun, 20 Aug 2017 21:28:20 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170820-probando-minio/</guid>
      <description>&lt;p&gt;Minio proporciona un servidor de almacenamiento distribuido compatible con el API de Amazon AWS S3.&lt;/p&gt;
&lt;p&gt;En esta entrada comento las pruebas que he estado realizando usando Minio tanto el cliente como el servidor en contenedores Docker.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Usando un contenedor sidecar para el almacenamiento</title>
      <link>https://onthedock.github.io/post/170819-usando-un-contenedor-sidecar/</link>
      <pubDate>Sat, 19 Aug 2017 09:51:23 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170819-usando-un-contenedor-sidecar/</guid>
      <description>&lt;p&gt;Como indicaba en la entrada la anterior entrada &lt;a href=&#34;https://onthedock.github.io/post/170817-almacenamiento-en-k8s-problema-abierto/&#34;&gt;Almacenamiento en Kubernetes: problema abierto&lt;/a&gt;, el problema de proporcionar almacenamiento persistente para las aplicaciones desplegadas en Kubernetes sigue sin tener una solución general.&lt;/p&gt;
&lt;p&gt;En este artículo comento una solución particular al problema del almacenamiento basada en el uso de un contenedor &lt;em&gt;sidecar&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Play With Kubernetes</title>
      <link>https://onthedock.github.io/post/170818-play-with-k8s/</link>
      <pubDate>Fri, 18 Aug 2017 20:25:31 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170818-play-with-k8s/</guid>
      <description>&lt;p&gt;Hace unas semanas descubrí el sitio &lt;a href=&#34;http://play-with-k8s.com&#34;&gt;PWK&lt;/a&gt;, &lt;strong&gt;Play with Kubernetes&lt;/strong&gt;. Su creador, &lt;a href=&#34;https://medium.com/@marcosnils&#34;&gt;Marcos Nils&lt;/a&gt; explica en &lt;a href=&#34;https://medium.com/@marcosnils/introducing-pwk-play-with-k8s-159fcfeb787b&#34;&gt;Introducing PWK (Play with K8s)&lt;/a&gt; que tenía ganas de extender la plataforma PWD (Play with Docker) a Kubernetes.&lt;/p&gt;
&lt;p&gt;El sitio PWK permite montar clústers de Kubernetes y lanzar servicios replicados de manera rápida y sencilla. Se trata de un entorno donde realizar pruebas y &lt;em&gt;jugar&lt;/em&gt; durante cuatro horas con varias instancias de Docker sobre las que podemos usar &lt;code&gt;kubeadm&lt;/code&gt; para instalar y configurar Kubernetes, creando un clúster en menos de un minuto.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Troubleshooting: Creación de pods del tutorial &#39;StatefulSet Basics&#39;</title>
      <link>https://onthedock.github.io/post/170818-troubleshooting-creacion-de-pods-del-tutorial-statefulset-basics/</link>
      <pubDate>Fri, 18 Aug 2017 17:45:03 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170818-troubleshooting-creacion-de-pods-del-tutorial-statefulset-basics/</guid>
      <description>&lt;p&gt;Esta entrada es un registro de las diferentes acciones que realicé para conseguir que los &lt;em&gt;pods&lt;/em&gt; asociados al &lt;em&gt;StatefulSet&lt;/em&gt; del tutorial &lt;a href=&#34;https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/&#34;&gt;StatefulSet Basics&lt;/a&gt; se crearan correctamente.&lt;/p&gt;
&lt;p&gt;Lo publico como lo que es, un &lt;em&gt;log&lt;/em&gt; de todos los pasos que fui dando, en modo &lt;em&gt;ensayo y error&lt;/em&gt;, hasta que conseguí que los &lt;em&gt;pods&lt;/em&gt; se crearan con éxito. Mi intención al publicarlo no es tanto que sirva como referencia sino como archivo. Y si alguien se encuentra con un problema similar, que pueda consultar los pasos que he dado durante el &lt;em&gt;troubleshooting&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Como indicaba en el artículo anterior, quiero publicar un tutorial paso a paso con el proceso correcto para provisionar los &lt;em&gt;PersistentVolumes&lt;/em&gt; necesarios para el tutorial &lt;a href=&#34;https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/&#34;&gt;StatefulSet Basics&lt;/a&gt; del sitio de Kubernetes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Almacenamiento en Kubernetes: problema abierto</title>
      <link>https://onthedock.github.io/post/170817-almacenamiento-en-k8s-problema-abierto/</link>
      <pubDate>Thu, 17 Aug 2017 17:11:05 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170817-almacenamiento-en-k8s-problema-abierto/</guid>
      <description>&lt;p&gt;Leía el otro día que desde el principio la tendencia hacia los microservicios estaba pensada para las aplicaciones &lt;em&gt;stateless&lt;/em&gt;, es decir, sin &amp;ldquo;memoria&amp;rdquo; del estado, donde cada interacción con la aplicación se considera independiente del resto. El ejemplo clásico de aplicación &lt;em&gt;stateless&lt;/em&gt; es un servidor web. Así que no es de extrañar que la aplicación que siempre aparece en todo tutorial que se precie de Docker/Kubernetes  es Nginx.&lt;/p&gt;
&lt;p&gt;En el mundo real, sin embargo, la mayoría de aplicaciones requieren algún tipo de persistencia, incluso las webs más sencillas (así surgieron las &lt;em&gt;cookies&lt;/em&gt;). Pero por el momento, Kubernetes y el almacenamiento son dos conceptos que no combinan demasiado bien, aunque funcionan perfectamente por separado.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Asignar recursos de CPU y RAM a un contenedor</title>
      <link>https://onthedock.github.io/post/170729-asignar-recursos-de-cpu-y-ram-a-un-contenedor/</link>
      <pubDate>Sat, 29 Jul 2017 21:12:35 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170729-asignar-recursos-de-cpu-y-ram-a-un-contenedor/</guid>
      <description>&lt;p&gt;Cuando se crea un &lt;em&gt;pod&lt;/em&gt; se pueden reservar recursos de CPU y RAM para los contenedores que corren en el &lt;em&gt;pod&lt;/em&gt;. Para reservar recursos, usa el campo &lt;code&gt;resources: requests&lt;/code&gt; en el fichero de configuración. Para establecer límites, usa el campo &lt;code&gt;resources: limits&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Espacios de nombres en Kubernetes</title>
      <link>https://onthedock.github.io/post/170723-espacios-de-nombres-en-k8s/</link>
      <pubDate>Sun, 23 Jul 2017 20:04:45 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170723-espacios-de-nombres-en-k8s/</guid>
      <description>&lt;p&gt;Los &lt;a href=&#34;https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/&#34;&gt;&lt;em&gt;namespaces&lt;/em&gt; (espacios de nombres)&lt;/a&gt; en Kubernetes permiten establecer un nivel adicional de separación entre los contenedores que comparten los recursos de un clúster.&lt;/p&gt;
&lt;p&gt;Esto es especialmente útil cuando diferentes grupos de DevOps usan el mismo clúster y existe el riesgo potencial de colisión de nombres de los &lt;em&gt;pods&lt;/em&gt;, etc usados por los diferentes equipos.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Mi primera aplicación en Kubernetes</title>
      <link>https://onthedock.github.io/post/170716-mi-primera-app-en-kubernetes/</link>
      <pubDate>Sun, 16 Jul 2017 19:38:17 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170716-mi-primera-app-en-kubernetes/</guid>
      <description>&lt;p&gt;Después de &lt;a href=&#34;https://onthedock.github.io/post/170702-crear-un-cluster-de-un-solo-nodo/&#34;&gt;crear un cluster de un solo nodo&lt;/a&gt;, en esta entrada explico los pasos para publicar una aplicación en el clúster.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Crear un cluster de un solo nodo</title>
      <link>https://onthedock.github.io/post/170702-crear-un-cluster-de-un-solo-nodo/</link>
      <pubDate>Sun, 02 Jul 2017 23:14:22 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170702-crear-un-cluster-de-un-solo-nodo/</guid>
      <description>&lt;p&gt;Para tener un clúster de desarrollo con la versatilidad de poder hacer y deshacer cambios (usando los &lt;em&gt;snapshots&lt;/em&gt; de una máquina virtual), lo más sencillo es disponer de un clúster de Kubernetes de un solo nodo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>IP en mensaje prelogin</title>
      <link>https://onthedock.github.io/post/170702-ip-en-mensaje-prelogin/</link>
      <pubDate>Sun, 02 Jul 2017 22:07:18 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170702-ip-en-mensaje-prelogin/</guid>
      <description>&lt;p&gt;En la pantalla de &lt;em&gt;login&lt;/em&gt; en modo consola de los sistemas Linux se muestra un mensaje de bienvenida.&lt;/p&gt;
&lt;p&gt;En este artículo se muestra cómo hacer que se muestre la IP del equipo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instalación de Alpine linux</title>
      <link>https://onthedock.github.io/post/170604-instalacion-de-alpine-linux/</link>
      <pubDate>Sun, 04 Jun 2017 18:26:48 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170604-instalacion-de-alpine-linux/</guid>
      <description>&lt;p&gt;Alpine Linux se ha convertido en la distribución por defecto con la que construir contenedores.&lt;/p&gt;
&lt;p&gt;Alpine tiene sus propias particularidades, ya que no deriva de otra distribución, de manera que he pensado que sería una buena idea tener una máquina virtual con la que entrenarme.&lt;/p&gt;
&lt;p&gt;En este artículo explico qué diferencias he encontrado en Alpine.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Revisión de conceptos</title>
      <link>https://onthedock.github.io/post/170528-revision-de-conceptos/</link>
      <pubDate>Sun, 28 May 2017 07:59:31 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170528-revision-de-conceptos/</guid>
      <description>&lt;p&gt;Después de estabilizar el clúster, el siguiente paso es poner en marcha aplicaciones. Pero ¿qué es exactamente lo que hay que desplegar?: ¿&lt;em&gt;pods&lt;/em&gt;?, ¿&lt;em&gt;replication controllers&lt;/em&gt;?, ¿&lt;em&gt;deployments&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Muchos artículos empiezan creando el fichero YAML para un &lt;em&gt;pod&lt;/em&gt;, después construyen el &lt;em&gt;replication controller&lt;/em&gt;, etc&amp;hellip; Sin embargo, revisando la documentación oficial, crear &lt;em&gt;pods&lt;/em&gt; directamente en Kubernetes no tiene mucho sentido.&lt;/p&gt;
&lt;p&gt;En este artículo intento determinar qué objetos son los que deben crearse en un clúster Kubernetes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Introduccion a YAML</title>
      <link>https://onthedock.github.io/post/170525-introduccion-a-yaml/</link>
      <pubDate>Thu, 25 May 2017 18:34:11 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170525-introduccion-a-yaml/</guid>
      <description>&lt;p&gt;YAML es el lenguaje en el que se definen los &lt;em&gt;pods&lt;/em&gt;, los &lt;em&gt;deployments&lt;/em&gt; y demás estructuras en Kubernetes. Todos los artículos que he leído sobre cómo crear un fichero de definición del &lt;em&gt;pod&lt;/em&gt; (&lt;em&gt;deployment&lt;/em&gt;, etc) se centran en el &lt;strong&gt;contenido&lt;/strong&gt; del fichero.&lt;/p&gt;
&lt;p&gt;Pero en mi caso, echaba de menos una explicación de &lt;strong&gt;cómo&lt;/strong&gt; se crea el fichero, qué reglas se siguen a la hora de &lt;em&gt;describir&lt;/em&gt; la configuración en formato YAML.&lt;/p&gt;
&lt;p&gt;Afortunadamente el lenguaje YAML es muy sencillo y basta con conocer un par de estructuras para crear los ficheros de configuración de Kubernetes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Normas para estructurar ficheros implicados en la creación de contenedores</title>
      <link>https://onthedock.github.io/post/170520-normas-para-estructurar-ficheros-implicados-en-la-creacion-de-contenedores/</link>
      <pubDate>Sat, 20 May 2017 19:59:44 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170520-normas-para-estructurar-ficheros-implicados-en-la-creacion-de-contenedores/</guid>
      <description>&lt;p&gt;El proceso desde la creación a la ejecución del contenedor se puede separar en varias fases:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Creación de la imagen (mediante la redacción de un fichero &lt;code&gt;Dockerfile&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Construcción de la imagen&lt;/li&gt;
&lt;li&gt;Ejecución del contenedores&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Para tener los diferentes ficheros implicados en el proceso organizados de forma homogénea, me he autoimpuesto las siguientes reglas a la hora de estructurar los repositorios.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>El nodo k3 sigue colgandose por culpa de Flannel</title>
      <link>https://onthedock.github.io/post/170517-el-nodo-k3-sigue-colgandose-por-culpa-de-flannel/</link>
      <pubDate>Wed, 17 May 2017 21:02:21 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170517-el-nodo-k3-sigue-colgandose-por-culpa-de-flannel/</guid>
      <description>&lt;p&gt;En la entrada &lt;a href=&#34;https://onthedock.github.io/post/170506-troubleshooting-kubernetes-ii/&#34;&gt;Troubleshooting Kubernetes (II)&lt;/a&gt; encontré restos de la instalación de &lt;a href=&#34;https://github.com/coreos/flannel&#34;&gt;Flannel&lt;/a&gt; en la Raspberry Pi. Eliminé los &lt;em&gt;pods&lt;/em&gt; que hacían referencia a Flannel y conseguí que el nodo &lt;strong&gt;k2&lt;/strong&gt; no se volviera a colgar.&lt;/p&gt;
&lt;p&gt;Sin embargo, el problema sigue dándose en el nodo &lt;strong&gt;k3&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Revisando el contenido de &lt;code&gt;/var/lib/kubernetes/pods/&lt;/code&gt; he visto que algunos &lt;em&gt;pods&lt;/em&gt; hacían referencia, todavía, a Flannel.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Protege el acceso remoto via API a Docker</title>
      <link>https://onthedock.github.io/post/170507-protege-el-acceso-remoto-via-api-a-docker/</link>
      <pubDate>Sun, 07 May 2017 18:33:16 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170507-protege-el-acceso-remoto-via-api-a-docker/</guid>
      <description>&lt;p&gt;En el artículo &lt;a href=&#34;https://onthedock.github.io/post/170506-habilita-el-acceso-remoto-via-api-a-docker/&#34;&gt;Habilita el API remoto de Docker&lt;/a&gt; explicaba cómo configurar el acceso remoto al API de Docker. El problema es que de esta forma no hay manera de restringir el acceso.&lt;/p&gt;
&lt;p&gt;En este artículo protegemos el acceso usando TLS de manera que sólo se permitan conexiones que presenten un certificado firmado por una CA de confianza.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Configura un endpoint remoto en Portainer</title>
      <link>https://onthedock.github.io/post/170506-configura-un-endpoint-remoto-en-portainer/</link>
      <pubDate>Sat, 06 May 2017 17:38:20 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170506-configura-un-endpoint-remoto-en-portainer/</guid>
      <description>&lt;p&gt;En el artículo &lt;a href=&#34;https://onthedock.github.io/post/170429-portainer-para-gestionar-tus-contenedores-en-docker/&#34;&gt;Portainer para gestionar tus contenedores en Docker&lt;/a&gt; usamos &lt;strong&gt;Portainer&lt;/strong&gt; para gestionar el Docker Engine local.&lt;/p&gt;
&lt;p&gt;En el artículo &lt;a href=&#34;https://onthedock.github.io/post/170506-habilita-el-acceso-remoto-via-api-a-docker/&#34;&gt;Habilita el API remoto de Docker&lt;/a&gt; habilitamos el acceso remoto al API de Docker Engine.&lt;/p&gt;
&lt;p&gt;En este artículo configuramos &lt;strong&gt;Portainer&lt;/strong&gt; para conectar con un &lt;em&gt;endpoint&lt;/em&gt; remoto (el API expuesta de un Docker Engine).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Habilita el acceso remoto vía API a Docker</title>
      <link>https://onthedock.github.io/post/170506-habilita-el-acceso-remoto-via-api-a-docker/</link>
      <pubDate>Sat, 06 May 2017 15:23:36 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170506-habilita-el-acceso-remoto-via-api-a-docker/</guid>
      <description>&lt;p&gt;Portainer permite gestionar &lt;em&gt;endpoints&lt;/em&gt; remotos para Docker (y Docker Swarm) mediante el API REST de Docker Engine. El problema es que el API está desactivado por defecto.&lt;/p&gt;
&lt;p&gt;A continuación indico cómo activar y verificar el acceso remoto al API de Docker Engine.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Troubleshooting Kubernetes (II)</title>
      <link>https://onthedock.github.io/post/170506-troubleshooting-kubernetes-ii/</link>
      <pubDate>Sat, 06 May 2017 05:21:09 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170506-troubleshooting-kubernetes-ii/</guid>
      <description>&lt;p&gt;Sigo con el &lt;em&gt;troubleshooting&lt;/em&gt; del &lt;em&gt;cuelgue&lt;/em&gt; de los nodos sobre Raspberry Pi 3 del clúster.&lt;/p&gt;
&lt;p&gt;Ayer estuve &lt;em&gt;haciendo limpieza&lt;/em&gt; siguiendo &lt;em&gt;vagamente&lt;/em&gt; la recomendación de &lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/43593#issuecomment-288899231&#34;&gt;esta respuesta&lt;/a&gt; en el hilo &lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/43593#issuecomment-288899231&#34;&gt;Kubernetes memory consumption explosion&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instala Weave Net en Kubernetes 1.6</title>
      <link>https://onthedock.github.io/post/170505-instala-weave-net-en-kubernetes-1.6/</link>
      <pubDate>Fri, 05 May 2017 22:14:36 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170505-instala-weave-net-en-kubernetes-1.6/</guid>
      <description>&lt;p&gt;Una de las cosas que más me sorprenden de Kubernetes es que es necesario instalar una &lt;em&gt;capa de red&lt;/em&gt; sobre el clúster.&lt;/p&gt;
&lt;p&gt;En el caso concreto del que he obtenido las &lt;em&gt;capturas de pantalla&lt;/em&gt;, el clúster corre sobre máquinas virtuales con Debian Jessie.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Troubleshooting Kubernetes (I)</title>
      <link>https://onthedock.github.io/post/170430-troubleshooting-kubernetes-i/</link>
      <pubDate>Sun, 30 Apr 2017 15:24:35 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170430-troubleshooting-kubernetes-i/</guid>
      <description>&lt;p&gt;Tras la alegría inicial pensando que la configuración de &lt;em&gt;rsyslog&lt;/em&gt; era la causante de los cuelgues de las dos RPi 3 (&lt;a href=&#34;https://onthedock.github.io/post/170430-k3-colgado-de-nuevo/&#34;&gt;El nodo k3 del clúster colgado de nuevo&lt;/a&gt;), pasadas unas horas los dos nodos &lt;strong&gt;k2&lt;/strong&gt; y &lt;strong&gt;k3&lt;/strong&gt; han dejado de responder de nuevo.&lt;/p&gt;
&lt;p&gt;Así que es el momento de atacar el problema de forma algo más sistemática. Para ello seguiré las instrucciones que proporcina la página de Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/&#34;&gt;Troubleshooting Clusters&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Errores sobre Orphaned pods en syslog</title>
      <link>https://onthedock.github.io/post/170430-errores-sobre-orphaned-pods-en-syslog/</link>
      <pubDate>Sun, 30 Apr 2017 12:55:44 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170430-errores-sobre-orphaned-pods-en-syslog/</guid>
      <description>&lt;p&gt;Los nodos &lt;strong&gt;k2&lt;/strong&gt; y &lt;strong&gt;k3&lt;/strong&gt; del clúster dejan de responder pasadas unas horas. La única manera de solucionarlo es reiniciar los nodos. Siguiendo con la revisión de logs, he encontrado que se genera una gran cantidad de entradas en &lt;em&gt;syslog&lt;/em&gt; en referencia a &lt;em&gt;orphaned pods&lt;/em&gt;. Además, el número de estos errores no para de crecer &lt;strong&gt;rápidamente&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>El nodo k3 del clúster colgado de nuevo</title>
      <link>https://onthedock.github.io/post/170430-k3-colgado-de-nuevo/</link>
      <pubDate>Sun, 30 Apr 2017 11:39:20 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170430-k3-colgado-de-nuevo/</guid>
      <description>&lt;p&gt;En la entrada anterior &lt;a href=&#34;https://onthedock.github.io/post/170430-multiples-mensajes-action-17-suspended/&#34;&gt;Múltiples mensajes &amp;lsquo;action 17 suspended&amp;rsquo; en los logs&lt;/a&gt; comentaba que estaba a la espera de obtener resultados; después de apenas unas horas, ya los tengo: &lt;strong&gt;k3&lt;/strong&gt; se ha vuelto a &lt;em&gt;colgar&lt;/em&gt; mientras que &lt;strong&gt;k2&lt;/strong&gt; no.&lt;/p&gt;
&lt;p&gt;Este resultado parece demostrar que la mala configuración de &lt;em&gt;rsyslog&lt;/em&gt; es la causante de los &lt;em&gt;cuelgues&lt;/em&gt; de las RPi 3 en el clúster de Kubernetes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Actualización&lt;/strong&gt;: El nodo &lt;strong&gt;k2&lt;/strong&gt; sobre RPi3 sigue colgándose :(&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Actualización II&lt;/strong&gt;: &lt;a href=&#34;https://onthedock.github.io/post/170506-troubleshooting-kubernetes-ii/&#34;&gt;Parece solucionado&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Múltiples mensajes &#39;action 17 suspended&#39; en los logs</title>
      <link>https://onthedock.github.io/post/170430-multiples-mensajes-action-17-suspended/</link>
      <pubDate>Sun, 30 Apr 2017 08:44:27 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170430-multiples-mensajes-action-17-suspended/</guid>
      <description>&lt;p&gt;Investigando las causas por las que los dos nodos con Raspberry Pi 3 se &lt;em&gt;cuelgan&lt;/em&gt;, he encontrado múltiples apariciones de este mensaje en &lt;code&gt;/var/log/messages&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34; data-lang=&#34;log&#34;&gt;Apr 30 06:40:42 k3 rsyslogd-2007: action &#39;action 17&#39; suspended, next retry is Sun Apr 30 06:41:12 2017 [try http://www.rsyslog.com/e/2007 ]
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Portainer para gestionar tus contenedores en Docker</title>
      <link>https://onthedock.github.io/post/170429-portainer-para-gestionar-tus-contenedores-en-docker/</link>
      <pubDate>Sat, 29 Apr 2017 12:55:04 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170429-portainer-para-gestionar-tus-contenedores-en-docker/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://portainer.io/&#34;&gt;Portainer&lt;/a&gt; es una herramienta ligera y &lt;em&gt;open-source&lt;/em&gt; de gestión de contenedores sobre Docker (o Docker Swarm). Portainer ofrece una interfaz gráfica para gestionar el &lt;em&gt;host&lt;/em&gt; Docker desde cualquier navegador, tiene soporte para Raspberry Pi y se puede desplegar como un simple contenedor.&lt;/p&gt;
&lt;p&gt;Espero que este artículo ayude a todos aquellos que tengan ganas de probar Portainer y evitarles los problemas que me he encontrado yo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Solución al error de instalación de Kubernetes en Debian Jessie (Missing cgroups: memory)</title>
      <link>https://onthedock.github.io/post/170422-solucion-al-error-missing-cgroups-memory-en-debian-jessie/</link>
      <pubDate>Sat, 22 Apr 2017 07:57:14 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170422-solucion-al-error-missing-cgroups-memory-en-debian-jessie/</guid>
      <description>&lt;p&gt;Al lanzar la inicialización del clúster con &lt;code&gt;kubeadm init&lt;/code&gt; en Debian Jessie, las comprobaciones inciales indican que no se encuentran los &lt;em&gt;cgroups&lt;/em&gt; para la memoria (échale un vistazo al artículo &lt;a href=&#34;https://onthedock.github.io/post/170417-instalacion-de-kubernetes-falla-missing-cgroups-memory/&#34;&gt;La instalación de Kubernetes falla en Debian Jessie (missing cgroups: memory)&lt;/a&gt;). Los &lt;em&gt;cgroups&lt;/em&gt; son una de las piezas fundamentales en las que se basa Docker para &lt;em&gt;aislar&lt;/em&gt; los procesos de los contenedores, por lo que la inicialización del clúster de Kubernetes se detiene.&lt;/p&gt;
&lt;p&gt;La solución es tan sencilla como habilitar los &lt;em&gt;cgroups&lt;/em&gt; durante el arranque.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>La instalación de Kubernetes falla en Debian Jessie (Missing cgroups: memory)</title>
      <link>https://onthedock.github.io/post/170417-instalacion-de-kubernetes-falla-missing-cgroups-memory/</link>
      <pubDate>Mon, 17 Apr 2017 19:38:11 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170417-instalacion-de-kubernetes-falla-missing-cgroups-memory/</guid>
      <description>&lt;p&gt;La instalación de Kubernetes se realiza de forma casi automática gracias al &lt;em&gt;script&lt;/em&gt; &lt;code&gt;kubeadm&lt;/code&gt;. Sólo hay que seguir las instrucciones de &lt;a href=&#34;https://kubernetes.io/docs/getting-started-guides/kubeadm/&#34;&gt;Installing Kubernetes on Linux with kubeadm&lt;/a&gt; y la salida por pantalla del propio &lt;em&gt;script&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cómo agregar un nodo a un cluster Kubernetes</title>
      <link>https://onthedock.github.io/post/170417-como-agregar-un-nodo-a-un-cluster-kubernetes/</link>
      <pubDate>Sat, 15 Apr 2017 16:27:30 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170417-como-agregar-un-nodo-a-un-cluster-kubernetes/</guid>
      <description>&lt;p&gt;Después de realizar la instalación del nodo &lt;em&gt;master&lt;/em&gt; del clúster Kubernetes, el siguiente paso es agregar nodos adicionales al clúster. Es en estos nodos donde se van a planificar los &lt;em&gt;pods&lt;/em&gt; que realizan las funciones &lt;em&gt;productivas&lt;/em&gt; del clúster (en el nodo &lt;em&gt;master&lt;/em&gt; sólo realiza tareas de gestión del clúster).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Error: The connection to the server localhost:8080 was refused</title>
      <link>https://onthedock.github.io/post/170414-error_the-connection-to-the-server-was-refused/</link>
      <pubDate>Fri, 14 Apr 2017 18:10:34 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170414-error_the-connection-to-the-server-was-refused/</guid>
      <description>&lt;p&gt;Después de &lt;a href=&#34;https://onthedock.github.io/post/170410-k8s-en-rpi-teaser/&#34;&gt;conseguir arrancar Kubernetes tras la instalación&lt;/a&gt;, al intentar ejecutar comandos vía &lt;code&gt;kubectl&lt;/code&gt; obtengo el mensaje de error &lt;code&gt;The connection to the server localhost:8080 was refused - did you specify the right host or port?&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;A continuación explico cómo solucionar el error y evitar que vuelva a mostrarse.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes en la Raspberry Pi (teaser)</title>
      <link>https://onthedock.github.io/post/170410-k8s-en-rpi-teaser/</link>
      <pubDate>Mon, 10 Apr 2017 22:45:28 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170410-k8s-en-rpi-teaser/</guid>
      <description>&lt;figure&gt;&lt;img src=&#34;https://onthedock.github.io/images/170410/itsalive.jpg&#34;/&gt;
&lt;/figure&gt;</description>
    </item>
    
    <item>
      <title>Docker-engine vs Docker.io</title>
      <link>https://onthedock.github.io/post/170410-docker-engine_vs_docker.io/</link>
      <pubDate>Mon, 10 Apr 2017 21:30:31 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170410-docker-engine_vs_docker.io/</guid>
      <description>&lt;p&gt;En función de la distribución que uses, verás que el paquete de instalación de Docker es &lt;code&gt;docker-engine&lt;/code&gt; o &lt;code&gt;docker.io&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;¿Cuál es la diferencia entre uno y otro?&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Acciones previas a la instalación de Kubernetes en Raspberry Pi</title>
      <link>https://onthedock.github.io/post/170409-acciones-previas-instalacion-rpi/</link>
      <pubDate>Sun, 09 Apr 2017 21:34:16 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170409-acciones-previas-instalacion-rpi/</guid>
      <description>&lt;p&gt;Uno de los objetivos motivadores de la existencia de este blog es instalar un clúster de Kubernetes sobre Raspberry Pi. Este artículo se centra en las tareas previas a la instalación en sí.&lt;/p&gt;
&lt;p&gt;Kubernetes requiere una instalación previa de Docker, una tarea simplificada gracias a HypriotOS, la &lt;em&gt;distro&lt;/em&gt; creada específicamente con este fin.&lt;/p&gt;
&lt;p&gt;El siguiente paso, la instalación de Kubernetes en la Raspberry será objeto de otra(s) entrada(s). Pero sin duda esta tarea sería mucho más complicada sin las contribuciones del joven finlandés &lt;a href=&#34;https://www.cncf.io/blog/2016/11/29/diversity-scholarship-series-programming-journey-becoming-kubernetes-maintainer/&#34;&gt;Lucas Käldström&lt;/a&gt; y su proyecto -ahora integrado la rama principal- &lt;a href=&#34;https://github.com/luxas/kubernetes-on-arm&#34;&gt;Kubernetes on ARM&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Contenedores y volúmenes de datos en el host</title>
      <link>https://onthedock.github.io/post/170408-contenedores-y-volumenes-en-el-host/</link>
      <pubDate>Sat, 08 Apr 2017 05:53:59 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170408-contenedores-y-volumenes-en-el-host/</guid>
      <description>&lt;p&gt;Ayer leía el artículo &lt;a href=&#34;https://thenewstack.io/containers-storage-arent-yet/&#34;&gt;Containers and Storage: Why We Aren’t There Yet&lt;/a&gt; y recordaba los &lt;em&gt;quebraderos de cabeza&lt;/em&gt; que tuve intentado crear una serie de contenedores accediendo a un volumen de datos.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Publica en Github Pages</title>
      <link>https://onthedock.github.io/post/170403-publica-en-github-pages/</link>
      <pubDate>Mon, 03 Apr 2017 22:38:35 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170403-publica-en-github-pages/</guid>
      <description>&lt;p&gt;Cómo publicar el sitio web generado con Hugo en GitHub Pages.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>De Blogger a Hugo</title>
      <link>https://onthedock.github.io/post/170401-de-blogger-a-hugo/</link>
      <pubDate>Sat, 01 Apr 2017 18:10:12 +0200</pubDate>
      
      <guid>https://onthedock.github.io/post/170401-de-blogger-a-hugo/</guid>
      <description>&lt;p&gt;Porqué me estoy planteando dejar Blogger y pasar a un sitio estático gracias a Hugo.&lt;/p&gt;
&lt;p&gt;Hugo es un &lt;em&gt;generador de sitios estáticos&lt;/em&gt; a partir de ficheros en formato &lt;em&gt;markdown&lt;/em&gt;. Hugo aplica una plantilla al contenido de los ficheros en formato &lt;em&gt;markdon&lt;/em&gt; y crea los ficheros HTML.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Configura curl para usar un proxy</title>
      <link>https://onthedock.github.io/post/170111-configura-curl-para-usar-proxy/</link>
      <pubDate>Wed, 11 Jan 2017 08:22:56 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/170111-configura-curl-para-usar-proxy/</guid>
      <description>&lt;p&gt;Cómo configurar &lt;code&gt;curl&lt;/code&gt; para salir a internet a través de un &lt;em&gt;proxy&lt;/em&gt; que requiere autenticación.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Instala Docker en Ubuntu Server 16.04</title>
      <link>https://onthedock.github.io/post/170110-instala-docker-en-ubuntu-server-16.04/</link>
      <pubDate>Tue, 10 Jan 2017 15:12:46 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/170110-instala-docker-en-ubuntu-server-16.04/</guid>
      <description>&lt;p&gt;Cómo instalar Docker en Ubuntu Server 16.04.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Configura el proxy para APT en Ubuntu Server 16.04</title>
      <link>https://onthedock.github.io/post/170110-configura-apt-en-ubuntu-server-16.04/</link>
      <pubDate>Tue, 10 Jan 2017 15:01:55 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/170110-configura-apt-en-ubuntu-server-16.04/</guid>
      <description>&lt;p&gt;Cómo configurar &lt;code&gt;apt&lt;/code&gt; para salir a internet a través de un &lt;em&gt;proxy&lt;/em&gt; que requiere autenticación.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Introducción a Hypriot OS</title>
      <link>https://onthedock.github.io/post/161105-introduccion-a-hypriotos/</link>
      <pubDate>Sat, 05 Nov 2016 10:37:47 +0100</pubDate>
      
      <guid>https://onthedock.github.io/post/161105-introduccion-a-hypriotos/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://blog.hypriot.com/about/#hypriotos:6083a88ee3411b0d17ce02d738f69d47&#34;&gt;HypriotOS&lt;/a&gt; es un sistema operativo basado en &lt;a href=&#34;http://www.debian.org/&#34;&gt;Debian&lt;/a&gt; optimizado para ejecutar &lt;a href=&#34;http://www.docker.com/&#34;&gt;Docker&lt;/a&gt; en plataformas ARM como las &lt;a href=&#34;https://www.raspberrypi.org/&#34;&gt;Raspberry Pi&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
